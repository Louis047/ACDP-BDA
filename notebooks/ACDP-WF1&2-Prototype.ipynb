{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm_QqT-A-oW_",
        "outputId": "71025deb-a048-4122-c957-fa2b5c036805"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.13), please consider upgrading to the latest version (0.4.1).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/usmanshams/nyc-yellow-taxi-dataset-2024?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 537M/537M [00:05<00:00, 98.4MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/usmanshams/nyc-yellow-taxi-dataset-2024/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"usmanshams/nyc-yellow-taxi-dataset-2024\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Batch Data Ingestion"
      ],
      "metadata": {
        "id": "wQ2qmDnmFfoE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "qAVi5bL8_81H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"ACADP-Ingestion\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "B89XIj-1ABT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Construct the full path to the taxi_zone_lookup.csv file\n",
        "csv_file_path = os.path.join(path, \"nyc_yellow_taxi_dataset\", \"taxi_zone_lookup.csv\")\n",
        "\n",
        "# Load the CSV file into a Spark DataFrame\n",
        "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(csv_file_path)\n",
        "\n",
        "print(\"DataFrame loaded successfully.\")\n",
        "df.show(5)\n",
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-WVC4NOAGlW",
        "outputId": "685fd45d-5574-4b3c-d6f3-1d1a5e979deb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DataFrame loaded successfully.\n",
            "+----------+-------------+--------------------+------------+\n",
            "|LocationID|      Borough|                Zone|service_zone|\n",
            "+----------+-------------+--------------------+------------+\n",
            "|         1|          EWR|      Newark Airport|         EWR|\n",
            "|         2|       Queens|         Jamaica Bay|   Boro Zone|\n",
            "|         3|        Bronx|Allerton/Pelham G...|   Boro Zone|\n",
            "|         4|    Manhattan|       Alphabet City| Yellow Zone|\n",
            "|         5|Staten Island|       Arden Heights|   Boro Zone|\n",
            "+----------+-------------+--------------------+------------+\n",
            "only showing top 5 rows\n",
            "root\n",
            " |-- LocationID: integer (nullable = true)\n",
            " |-- Borough: string (nullable = true)\n",
            " |-- Zone: string (nullable = true)\n",
            " |-- service_zone: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schema Inference & Validation"
      ],
      "metadata": {
        "id": "H_nDwxDVFbQJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G40xCNa5Apa6",
        "outputId": "41d1c2ba-7775-4639-a08c-1218bf0ed12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- LocationID: integer (nullable = true)\n",
            " |-- Borough: string (nullable = true)\n",
            " |-- Zone: string (nullable = true)\n",
            " |-- service_zone: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = df.withColumn(\"fare_amount\", df.fare_amount.cast(\"double\"))\n",
        "# df = df.withColumn(\"trip_distance\", df.trip_distance.cast(\"double\"))\n",
        "\n",
        "# The columns 'fare_amount' and 'trip_distance' are not present in the current 'df'\n",
        "# which was loaded from 'taxi_zone_lookup.csv'.\n",
        "# If you intend to work with these columns, please load a different dataset\n",
        "# (e.g., one of the yellow_tripdata_XXXX-XX.parquet files) into your DataFrame."
      ],
      "metadata": {
        "id": "-jrca4GJAucy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bc99790"
      },
      "source": [
        "Let's explore the distribution of `Borough` in the `taxi_zone_lookup` DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af2d4655",
        "outputId": "94cc6e6e-b7bf-41ab-9118-7bee7677a66a"
      },
      "source": [
        "df.groupBy(\"Borough\").count().orderBy(\"count\", ascending=False).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------------+-----+\n",
            "|      Borough|count|\n",
            "+-------------+-----+\n",
            "|       Queens|   69|\n",
            "|    Manhattan|   69|\n",
            "|     Brooklyn|   61|\n",
            "|        Bronx|   43|\n",
            "|Staten Island|   20|\n",
            "|          EWR|    1|\n",
            "|      Unknown|    1|\n",
            "|          N/A|    1|\n",
            "+-------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Handle Missing Values"
      ],
      "metadata": {
        "id": "U1GktsNNFXCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for f in os.listdir(path):\n",
        "    print(f)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psz9T-cuBhzw",
        "outputId": "ba2fbe59-3f4b-43c6-ebeb-f9331ca8545d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nyc_yellow_taxi_dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read \\\n",
        "    .parquet(f\"{path}/nyc_yellow_taxi_dataset/yellow_tripdata_*.parquet\")"
      ],
      "metadata": {
        "id": "wjjpcbMSEoOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toxSpP_1E4H8",
        "outputId": "30f75dce-3ef9-4ff1-ce44-f164f6c6031b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- VendorID: integer (nullable = true)\n",
            " |-- tpep_pickup_datetime: timestamp_ntz (nullable = true)\n",
            " |-- tpep_dropoff_datetime: timestamp_ntz (nullable = true)\n",
            " |-- passenger_count: long (nullable = true)\n",
            " |-- trip_distance: double (nullable = true)\n",
            " |-- RatecodeID: long (nullable = true)\n",
            " |-- store_and_fwd_flag: string (nullable = true)\n",
            " |-- PULocationID: integer (nullable = true)\n",
            " |-- DOLocationID: integer (nullable = true)\n",
            " |-- payment_type: long (nullable = true)\n",
            " |-- fare_amount: double (nullable = true)\n",
            " |-- extra: double (nullable = true)\n",
            " |-- mta_tax: double (nullable = true)\n",
            " |-- tip_amount: double (nullable = true)\n",
            " |-- tolls_amount: double (nullable = true)\n",
            " |-- improvement_surcharge: double (nullable = true)\n",
            " |-- total_amount: double (nullable = true)\n",
            " |-- congestion_surcharge: double (nullable = true)\n",
            " |-- Airport_fee: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=[\n",
        "    \"fare_amount\",\n",
        "    \"trip_distance\",\n",
        "    \"passenger_count\"\n",
        "])\n"
      ],
      "metadata": {
        "id": "6nrej1h2E8k4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.fillna({\"payment_type\": \"UNKNOWN\"})"
      ],
      "metadata": {
        "id": "BEAuP2TFFD60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding & Normalization"
      ],
      "metadata": {
        "id": "26AopOCoFKCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer"
      ],
      "metadata": {
        "id": "xW__huaOFK3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(\n",
        "    inputCol=\"payment_type\",\n",
        "    outputCol=\"payment_type_idx\"\n",
        ")\n",
        "\n",
        "df = indexer.fit(df).transform(df)"
      ],
      "metadata": {
        "id": "muzT80luFO_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalization"
      ],
      "metadata": {
        "id": "k0fmtexhFmvo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "6cFB32qcFpAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\n",
        "    \"fare_amount_norm\",\n",
        "    col(\"fare_amount\") / 500.0\n",
        ")"
      ],
      "metadata": {
        "id": "6OzESEP4FsFU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Bounding"
      ],
      "metadata": {
        "id": "NrO2AqMEFxXL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when"
      ],
      "metadata": {
        "id": "vnmrQjdMFx5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.withColumn(\n",
        "    \"fare_amount\",\n",
        "    when(df.fare_amount < 0, 0)\n",
        "    .when(df.fare_amount > 500, 500)\n",
        "    .otherwise(df.fare_amount)\n",
        ")\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"trip_distance\",\n",
        "    when(df.trip_distance < 0, 0)\n",
        "    .when(df.trip_distance > 200, 200)\n",
        "    .otherwise(df.trip_distance)\n",
        ")\n",
        "\n",
        "df = df.withColumn(\n",
        "    \"passenger_count\",\n",
        "    when(df.passenger_count < 1, 1)\n",
        "    .when(df.passenger_count > 8, 8)\n",
        "    .otherwise(df.passenger_count)\n",
        ")"
      ],
      "metadata": {
        "id": "l4IFXHfFF5Nc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Feature Statistics Generation"
      ],
      "metadata": {
        "id": "87wSKGtZF820"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.select(\n",
        "    \"fare_amount\",\n",
        "    \"trip_distance\",\n",
        "    \"passenger_count\"\n",
        ").describe().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwEmqCoCF9aM",
        "outputId": "ec8c5ee5-f944-4662-9546-93fbd37f6d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+------------------+------------------+------------------+\n",
            "|summary|       fare_amount|     trip_distance|   passenger_count|\n",
            "+-------+------------------+------------------+------------------+\n",
            "|  count|          30463713|          30463713|          30463713|\n",
            "|   mean|19.530663900347527|3.4160863207972207|1.3426768759277636|\n",
            "| stddev|18.778822761373913| 4.637725511074635|0.8068186061991545|\n",
            "|    min|               0.0|               0.0|                 1|\n",
            "|    max|             500.0|             200.0|                 8|\n",
            "+-------+------------------+------------------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupBy(\"payment_type\").count().show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFTYuvbWGDMb",
        "outputId": "9d8be92f-49d5-49a5-c662-a095094bd1d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------+\n",
            "|payment_type|   count|\n",
            "+------------+--------+\n",
            "|           1|24999870|\n",
            "|           3|  235960|\n",
            "|           2| 4599611|\n",
            "|           4|  628268|\n",
            "|           5|       4|\n",
            "+------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Outputs"
      ],
      "metadata": {
        "id": "LBrb_--7GH3S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.write.mode(\"overwrite\").parquet(\"bounded_nyc_taxi\")"
      ],
      "metadata": {
        "id": "g8CA0D3lGIr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 0 Load Required Libraries"
      ],
      "metadata": {
        "id": "I1Ie4xMDOdRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "import networkx as nx\n",
        "from sklearn.metrics import mutual_info_score\n",
        "from sklearn.preprocessing import KBinsDiscretizer\n"
      ],
      "metadata": {
        "id": "NgvZAooWOWcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1 Load a Sample (Scalability-Safe)*italicised text*"
      ],
      "metadata": {
        "id": "rVYiUrNUOeTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet(\"/content/bounded_nyc_taxi\")\n",
        "\n",
        "# sample 1–5% or fixed rows\n",
        "sample_df = df.sample(n=200_000, random_state=42)\n"
      ],
      "metadata": {
        "id": "QOnx01DWOiEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2 Initial Feature Filtering (Pruning)\n",
        " 2.1 Remove constant features\n"
      ],
      "metadata": {
        "id": "6ITxt7SPOyhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nunique = sample_df.nunique()\n",
        "valid_features = nunique[nunique > 1].index.tolist()\n",
        "sample_df = sample_df[valid_features]\n"
      ],
      "metadata": {
        "id": "StgxJNztO1Y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.2 Remove low-variance numerical features"
      ],
      "metadata": {
        "id": "LpvRdMTtO3zG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = sample_df.select_dtypes(include=np.number).columns\n",
        "variances = sample_df[num_cols].var()\n",
        "\n",
        "num_cols = variances[variances > 1e-4].index.tolist()\n"
      ],
      "metadata": {
        "id": "B03clGAmPN38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3 Approximate Pearson Correlation (Numerical)\n",
        "Compute only on filtered numeric features"
      ],
      "metadata": {
        "id": "G7cndi5oPQTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pearson_corr = sample_df[num_cols].corr(method=\"pearson\")\n"
      ],
      "metadata": {
        "id": "kpjrO7YzPUIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep only strong correlations"
      ],
      "metadata": {
        "id": "SRjcWyU-PWlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "THRESH = 0.4\n",
        "\n",
        "pearson_pairs = [\n",
        "    (i, j, pearson_corr.loc[i, j])\n",
        "    for i, j in combinations(num_cols, 2)\n",
        "    if abs(pearson_corr.loc[i, j]) >= THRESH\n",
        "]\n"
      ],
      "metadata": {
        "id": "fPGYpbATPZTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 4 Approximate Mutual Information (Categorical)\n",
        "4.1 Select categorical features"
      ],
      "metadata": {
        "id": "ukSzf2zUPdvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cat_cols = sample_df.select_dtypes(exclude=np.number).columns.tolist()\n"
      ],
      "metadata": {
        "id": "7lTDkZZHPgTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.2 Discretize (for MI feasibility)"
      ],
      "metadata": {
        "id": "nkih0w-UPiyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "disc = KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"uniform\")\n",
        "\n",
        "disc_df = sample_df[num_cols].copy()\n",
        "disc_df[num_cols] = disc.fit_transform(disc_df[num_cols])\n"
      ],
      "metadata": {
        "id": "frk7m44LPn9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.3 MI on sampled & pruned pairs only"
      ],
      "metadata": {
        "id": "Eodx4PiaPqux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MI_THRESH = 0.05\n",
        "mi_pairs = []\n",
        "\n",
        "for c1, c2 in combinations(cat_cols[:10], 2):  # cap for scalability\n",
        "    mi = mutual_info_score(sample_df[c1], sample_df[c2])\n",
        "    if mi >= MI_THRESH:\n",
        "        mi_pairs.append((c1, c2, mi))\n"
      ],
      "metadata": {
        "id": "S7xpvWboPtDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 5 Build Dependency Graph"
      ],
      "metadata": {
        "id": "5QQd8_VMPvur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.Graph()\n",
        "\n",
        "# Add Pearson edges\n",
        "for f1, f2, w in pearson_pairs:\n",
        "    G.add_edge(f1, f2, weight=abs(w))\n",
        "\n",
        "# Add MI edges\n",
        "for f1, f2, w in mi_pairs:\n",
        "    G.add_edge(f1, f2, weight=w)\n"
      ],
      "metadata": {
        "id": "bw3vnCwePzwT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 6 Graph-Based Feature Grouping\n",
        "Connected components = feature blocks"
      ],
      "metadata": {
        "id": "YavPD4MbP4PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_blocks = list(nx.connected_components(G))\n"
      ],
      "metadata": {
        "id": "z3POUsm3P70C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 7 Save Outputs (Deliverables)"
      ],
      "metadata": {
        "id": "rioJUz6OP-DB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save dependency edges\n",
        "edges_df = pd.DataFrame(\n",
        "    [(u, v, d[\"weight\"]) for u, v, d in G.edges(data=True)],\n",
        "    columns=[\"feature_1\", \"feature_2\", \"strength\"]\n",
        ")\n",
        "edges_df.to_csv(\"reduced_dependency_matrix.csv\", index=False)\n",
        "\n",
        "# Save blocks\n",
        "blocks_df = pd.DataFrame({\n",
        "    \"block_id\": range(len(feature_blocks)),\n",
        "    \"features\": [list(b) for b in feature_blocks]\n",
        "})\n",
        "blocks_df.to_csv(\"feature_blocks.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "pxig8lTsQEIH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}